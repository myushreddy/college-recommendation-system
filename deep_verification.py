"""
Deep Verification Script
========================
This script thoroughly checks the original datasets and cleaning results
"""

import pandas as pd
import numpy as np

print("\n" + "="*80)
print("COMPREHENSIVE DATA VERIFICATION")
print("="*80)

# ============================================================================
# DATASET 1: engineering colleges in India.csv
# ============================================================================
print("\n" + "="*80)
print("DATASET 1: engineering colleges in India.csv")
print("="*80)

try:
    df1_original = pd.read_csv('data/engineering colleges in India.csv')
    print(f"‚úì Loaded successfully: {len(df1_original)} rows")
    print(f"\nColumns ({len(df1_original.columns)}):")
    for i, col in enumerate(df1_original.columns, 1):
        print(f"  {i}. {col}")
    
    print(f"\nüìä Data Quality Issues Found:")
    
    # Check college names
    print(f"\n1. College Names:")
    names_with_trailing_space = df1_original['College Name'].str.endswith(' ').sum()
    names_with_leading_space = df1_original['College Name'].str.startswith(' ').sum()
    names_with_newline = df1_original['College Name'].str.contains('\n', na=False).sum()
    print(f"   - Names with trailing spaces: {names_with_trailing_space}")
    print(f"   - Names with leading spaces: {names_with_leading_space}")
    print(f"   - Names with newlines: {names_with_newline}")
    
    # Show examples
    print(f"\n   First 3 college names (raw):")
    for i, name in enumerate(df1_original['College Name'].head(3), 1):
        print(f"   {i}. {repr(name)}")
    
    # Check missing values
    print(f"\n2. Missing Values:")
    missing = df1_original.isna().sum()
    missing = missing[missing > 0]
    if len(missing) > 0:
        for col, count in missing.items():
            percentage = (count / len(df1_original)) * 100
            print(f"   - {col}: {count} ({percentage:.1f}%)")
    else:
        print("   ‚úì No missing values!")
    
    # Check courses
    print(f"\n3. Course Names:")
    courses_with_newline = df1_original['Courses'].str.contains('\n', na=False).sum()
    print(f"   - Courses with newlines: {courses_with_newline}")
    sample_course = df1_original['Courses'].iloc[0]
    print(f"   - Sample (first 100 chars): {repr(sample_course[:100])}")
    
    # Check fees
    print(f"\n4. Fee Structure:")
    print(f"   - Data type: {df1_original['Average Fees'].dtype}")
    print(f"   - Missing fees: {df1_original['Average Fees'].isna().sum()}")
    print(f"   - Sample fees (first 5):")
    for i, fee in enumerate(df1_original['Average Fees'].head(5), 1):
        print(f"     {i}. {fee} (type: {type(fee).__name__})")
    
    if df1_original['Average Fees'].notna().sum() > 0:
        valid_fees = df1_original['Average Fees'].dropna()
        print(f"   - Min fee: ‚Çπ{valid_fees.min():,.2f}")
        print(f"   - Max fee: ‚Çπ{valid_fees.max():,.2f}")
        print(f"   - Average fee: ‚Çπ{valid_fees.mean():,.2f}")

except Exception as e:
    print(f"‚ùå ERROR: {e}")

# ============================================================================
# DATASET 2: Engineering.csv
# ============================================================================
print("\n" + "="*80)
print("DATASET 2: Engineering.csv")
print("="*80)

try:
    # Try different encodings
    df2_original = None
    for encoding in ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']:
        try:
            df2_original = pd.read_csv('data/Engineering.csv', encoding=encoding)
            print(f"‚úì Loaded successfully with {encoding}: {len(df2_original)} rows")
            break
        except:
            continue
    
    if df2_original is None:
        print("‚ùå Could not load file with any encoding")
    else:
        print(f"\nColumns ({len(df2_original.columns)}):")
        for i, col in enumerate(df2_original.columns, 1):
            print(f"  {i}. {col}")
        
        print(f"\nüìä Data Quality Issues Found:")
        
        # Check college names
        print(f"\n1. College Names:")
        col_name = 'college name'
        if col_name in df2_original.columns:
            names_with_newline = df2_original[col_name].astype(str).str.contains('\n', na=False).sum()
            print(f"   - Names with newlines: {names_with_newline}")
            print(f"   - First 3 college names (raw):")
            for i, name in enumerate(df2_original[col_name].head(3), 1):
                print(f"   {i}. {repr(name)}")
        
        # Check courses
        print(f"\n2. Course Names:")
        if 'Course' in df2_original.columns:
            courses_with_newline = df2_original['Course'].astype(str).str.contains('\n', na=False).sum()
            print(f"   - Courses with newlines: {courses_with_newline}")
            print(f"   - Unique courses: {df2_original['Course'].nunique()}")
            print(f"   - Sample courses (first 5):")
            for i, course in enumerate(df2_original['Course'].head(5), 1):
                print(f"   {i}. {repr(course)}")
        
        # Check missing values
        print(f"\n3. Missing Values:")
        missing = df2_original.isna().sum()
        missing = missing[missing > 0]
        if len(missing) > 0:
            for col, count in missing.items():
                percentage = (count / len(df2_original)) * 100
                print(f"   - {col}: {count} ({percentage:.1f}%)")
        else:
            print("   ‚úì No missing values!")

except Exception as e:
    print(f"‚ùå ERROR: {e}")

# ============================================================================
# DATASET 3: NIRF Rankings
# ============================================================================
print("\n" + "="*80)
print("DATASET 3: NIRF Ranking for Engineering Colleges 2024.csv")
print("="*80)

try:
    df3_original = pd.read_csv('data/NIRF Ranking for Engineering Colleges 2024.csv')
    print(f"‚úì Loaded successfully: {len(df3_original)} rows")
    print(f"\nColumns ({len(df3_original.columns)}):")
    for i, col in enumerate(df3_original.columns, 1):
        print(f"  {i}. {repr(col)}")
    
    print(f"\nüìä Data Quality Issues Found:")
    
    # Check college names
    print(f"\n1. College Names:")
    print(f"   - First 5 college names:")
    for i, name in enumerate(df3_original['Name'].head(5), 1):
        print(f"   {i}. {name}")
    
    # Check missing values
    print(f"\n2. Missing Values:")
    missing = df3_original.isna().sum()
    missing = missing[missing > 0]
    if len(missing) > 0:
        for col, count in missing.items():
            print(f"   - {col}: {count}")
    else:
        print("   ‚úì No missing values!")
    
    # Check rankings
    print(f"\n3. Rankings:")
    print(f"   - Min rank: {df3_original['Rank'].min()}")
    print(f"   - Max rank: {df3_original['Rank'].max()}")
    print(f"   - Top 5:")
    for _, row in df3_original.head(5).iterrows():
        print(f"     {row['Rank']}. {row['Name']}")

except Exception as e:
    print(f"‚ùå ERROR: {e}")

# ============================================================================
# CHECK CLEANED FILES
# ============================================================================
print("\n" + "="*80)
print("VERIFYING CLEANED FILES")
print("="*80)

try:
    df1_cleaned = pd.read_csv('data/cleaned_engineering_colleges_india.csv')
    df2_cleaned = pd.read_csv('data/cleaned_engineering.csv')
    df3_cleaned = pd.read_csv('data/cleaned_nirf_rankings.csv')
    
    print(f"\n‚úì All cleaned files loaded successfully!")
    print(f"\nüìä Comparison:")
    print(f"\nDataset 1:")
    print(f"  Original rows: {len(df1_original)}")
    print(f"  Cleaned rows:  {len(df1_cleaned)}")
    print(f"  Missing values before: {df1_original.isna().sum().sum()}")
    print(f"  Missing values after:  {df1_cleaned.isna().sum().sum()}")
    
    print(f"\nDataset 2:")
    print(f"  Original rows: {len(df2_original)}")
    print(f"  Cleaned rows:  {len(df2_cleaned)}")
    
    print(f"\nDataset 3:")
    print(f"  Original rows: {len(df3_original)}")
    print(f"  Cleaned rows:  {len(df3_cleaned)}")
    
    # Check specific cleaning examples
    print(f"\n" + "="*80)
    print("CLEANING VERIFICATION EXAMPLES")
    print("="*80)
    
    print(f"\n1. College Name Cleaning:")
    print(f"   Before: {repr(df1_original['College Name'].iloc[0])}")
    print(f"   After:  {repr(df1_cleaned['College Name'].iloc[0])}")
    
    print(f"\n2. Course Name Cleaning (Dataset 2):")
    print(f"   Before: {repr(df2_original['Course'].iloc[2])}")
    print(f"   After:  {repr(df2_cleaned['Course'].iloc[2])}")
    
    print(f"\n3. Fee Normalization:")
    print(f"   Before: {df1_original['Average Fees'].iloc[0]} (type: {type(df1_original['Average Fees'].iloc[0]).__name__})")
    print(f"   After:  {df1_cleaned['Average Fees'].iloc[0]} (type: {type(df1_cleaned['Average Fees'].iloc[0]).__name__})")

except Exception as e:
    print(f"‚ùå ERROR checking cleaned files: {e}")

# ============================================================================
# FINAL SUMMARY
# ============================================================================
print("\n" + "="*80)
print("FINAL VERIFICATION SUMMARY")
print("="*80)

print(f"\n‚úÖ Original Datasets:")
print(f"   1. engineering colleges in India.csv: {len(df1_original)} rows")
print(f"   2. Engineering.csv: {len(df2_original)} rows")
print(f"   3. NIRF Rankings 2024.csv: {len(df3_original)} rows")

print(f"\n‚úÖ Cleaned Datasets:")
print(f"   1. cleaned_engineering_colleges_india.csv: {len(df1_cleaned)} rows")
print(f"   2. cleaned_engineering.csv: {len(df2_cleaned)} rows")
print(f"   3. cleaned_nirf_rankings.csv: {len(df3_cleaned)} rows")

print(f"\n‚úÖ Key Issues Fixed:")
print(f"   ‚úì College names standardized")
print(f"   ‚úì Missing values handled")
print(f"   ‚úì Course names cleaned (newlines removed)")
print(f"   ‚úì Fees normalized to numeric format")
print(f"   ‚úì Encoding issues resolved")

print(f"\n{'='*80}")
print("Verification complete!")
print("="*80)
